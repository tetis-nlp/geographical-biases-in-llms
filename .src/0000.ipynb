{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographical Biases in Large Language Models (LLMs)\n",
    "\n",
    "This tutorial aims to identify geographical biases propagated by LLMs.\n",
    "\n",
    "1. Spatial disparities in geographical knowledge\n",
    "2. Spatial information coverage in training datasets\n",
    "3. Correlation between geographic distance and semantic distance\n",
    "4. Anomaly between geographical distance and semantic distance\n",
    "\n",
    "**Authors**\n",
    "\n",
    "| Author      | Affiliation            |\n",
    "|-------------|------------------------|\n",
    "| Rémy Decoupes    | INRAE / TETIS      |\n",
    "| Mathieu Roche  | CIRAD / TETIS |\n",
    "| Maguelonne Teisseire | INRAE / TETIS            |\n",
    "\n",
    "![TETIS](https://www.umr-tetis.fr/images/logo-header-tetis.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (0.43.0)\n",
      "Requirement already satisfied: torch in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from bitsandbytes) (2.2.2)\n",
      "Requirement already satisfied: numpy in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Collecting transformers==4.39\n",
      "  Downloading transformers-4.39.0-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from transformers==4.39) (3.13.3)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.39)\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from transformers==4.39) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from transformers==4.39) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from transformers==4.39) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from transformers==4.39) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from transformers==4.39) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39)\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from transformers==4.39) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from transformers==4.39) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->transformers==4.39) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->transformers==4.39) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->transformers==4.39) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->transformers==4.39) (2024.2.2)\n",
      "Downloading transformers-4.39.0-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.0\n",
      "    Uninstalling transformers-4.32.0:\n",
      "      Successfully uninstalled transformers-4.32.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "accelerate 0.29.0.dev0 requires huggingface-hub<0.21.0, but you have huggingface-hub 0.22.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.22.2 tokenizers-0.15.2 transformers-4.39.0\n",
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-t52gry_v\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-t52gry_v\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 02b5aeddf9c1ea11451f10a8a26da7e5df8cca4a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from peft==0.10.1.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from peft==0.10.1.dev0) (24.0)\n",
      "Requirement already satisfied: psutil in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from peft==0.10.1.dev0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from peft==0.10.1.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from peft==0.10.1.dev0) (2.2.2)\n",
      "Requirement already satisfied: transformers in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from peft==0.10.1.dev0) (4.39.0)\n",
      "Requirement already satisfied: tqdm in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from peft==0.10.1.dev0) (4.66.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from peft==0.10.1.dev0) (0.29.0.dev0)\n",
      "Requirement already satisfied: safetensors in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from peft==0.10.1.dev0) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from peft==0.10.1.dev0) (0.22.2)\n",
      "Collecting huggingface-hub>=0.17.0 (from peft==0.10.1.dev0)\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.1.dev0) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.1.dev0) (2024.3.1)\n",
      "Requirement already satisfied: requests in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.1.dev0) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.1.dev0) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.10.1.dev0) (12.4.127)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from transformers->peft==0.10.1.dev0) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from transformers->peft==0.10.1.dev0) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.10.1.dev0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.1.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.1.dev0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.1.dev0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.1.dev0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.10.1.dev0) (1.3.0)\n",
      "Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.22.2\n",
      "    Uninstalling huggingface-hub-0.22.2:\n",
      "      Successfully uninstalled huggingface-hub-0.22.2\n",
      "Successfully installed huggingface-hub-0.20.3\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-spe6hoos\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-spe6hoos\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit d96a5aa730805e37176b8756339b9c01b66100b5\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from accelerate==0.29.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from accelerate==0.29.0.dev0) (24.0)\n",
      "Requirement already satisfied: psutil in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from accelerate==0.29.0.dev0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from accelerate==0.29.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from accelerate==0.29.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub<0.21.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from accelerate==0.29.0.dev0) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from accelerate==0.29.0.dev0) (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (2024.3.1)\n",
      "Requirement already satisfied: requests in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.29.0.dev0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from requests->huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.29.0.dev0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Installation\n",
    "!pip install -U bitsandbytes\n",
    "!pip install transformers==4.37.2\n",
    "!pip install -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -U git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "\n",
    "list_of_models = {\n",
    "    'bert': {\n",
    "        'name': 'bert-base-uncased',\n",
    "        'tokenizer': BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "        'model': BertModel.from_pretrained('bert-base-uncased'),\n",
    "        'mask': \"[MASK]\",\n",
    "        'type': \"SLM\"\n",
    "    },\n",
    "    'bert-base-multilingual-uncased':{\n",
    "        'name': 'bert-base-multilingual-uncased',\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('bert-base-multilingual-uncased'),\n",
    "        'model': BertModel.from_pretrained('bert-base-multilingual-uncased'),\n",
    "        'mask': \"[MASK]\",\n",
    "        'type': \"SLM\"\n",
    "    },\n",
    "    'roberta': {\n",
    "        'name': 'roberta-base',\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('roberta-base'),\n",
    "        'model': RobertaModel.from_pretrained('roberta-base'),\n",
    "        'mask': \"<mask>\",\n",
    "        'type': \"SLM\"\n",
    "    },\n",
    "    'xlm-roberta-base': {\n",
    "        'name': 'xlm-roberta-base',\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('xlm-roberta-base'),\n",
    "        'model': RobertaModel.from_pretrained('xlm-roberta-base'),\n",
    "        'mask': \"<mask>\",\n",
    "        'type': \"SLM\"\n",
    "    },\n",
    "    'mistral': {\n",
    "        'name': 'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "        'type': \"LLM_local\"\n",
    "    },\n",
    "    'llama2': {\n",
    "        'name': 'meta-llama/Llama-2-7b-chat-hf',\n",
    "        'type': \"LLM_local\"\n",
    "    },\n",
    "    'chatgpt':{\n",
    "        'name': 'gpt-3.5-turbo-0301',\n",
    "        'type': \"LLM_remote_api\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initiate API Key**\n",
    "\n",
    "- HuggingFace \n",
    "- OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_API_TOKEN = input(\"Your huggingFace API Key\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spatial Disparities In Geographical Knowledge\n",
    "\n",
    "We will use 2 different types of language models: Small Language Model (SLM) and Large Language Model (LLM):\n",
    "\n",
    "\n",
    "- For SLMs: we will use the HuggingFace library transformers\n",
    "- For LLMs: 2 methods, through API with OpenAI (ChatGPT) or through local inference for Mistral or llama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of SLMs: ['bert-base-uncased', 'bert-base-multilingual-uncased', 'roberta-base', 'xlm-roberta-base']\n",
      "List of LLMs local inference: ['mistralai/Mistral-7B-Instruct-v0.1', 'meta-llama/Llama-2-7b-chat-hf']\n",
      "List of LLMs local inference: ['gpt-3.5-turbo-0301']\n"
     ]
    }
   ],
   "source": [
    "SLMs = {key: value for key, value in list_of_models.items() if 'type' in value and value['type'] == 'SLM'}\n",
    "print(f\"List of SLMs: {[value['name'] for value in SLMs.values()]}\")\n",
    "\n",
    "local_LLMs = {key: value for key, value in list_of_models.items() if 'type' in value and value['type'] == 'LLM_local'}\n",
    "print(f\"List of LLMs local inference: {[value['name'] for value in local_LLMs.values()]}\")\n",
    "\n",
    "api_LLMs = {key: value for key, value in list_of_models.items() if 'type' in value and value['type'] == 'LLM_remote_api'}\n",
    "print(f\"List of LLMs local inference: {[value['name'] for value in api_LLMs.values()]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Example of probing geographical knowledge\n",
    "\n",
    "Let's ask Roberta-base from which country Taipei is the capital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [{'score': 0.8915017247200012, 'token': 6951, 'token_str': ' Taiwan', 'sequence': 'Taipei is capital of Taiwan'}, {'score': 0.05331902578473091, 'token': 436, 'token_str': ' China', 'sequence': 'Taipei is capital of China'}, {'score': 0.025364302098751068, 'token': 1429, 'token_str': ' Japan', 'sequence': 'Taipei is capital of Japan'}, {'score': 0.011096514761447906, 'token': 6547, 'token_str': ' Thailand', 'sequence': 'Taipei is capital of Thailand'}, {'score': 0.006269776728004217, 'token': 1101, 'token_str': ' Korea', 'sequence': 'Taipei is capital of Korea'}]\n",
      "Predicted token:  Taiwan\n"
     ]
    }
   ],
   "source": [
    "fill_mask = pipeline(task=\"fill-mask\", model='roberta-base')\n",
    "masked_sentence = f'Taipei is capital of <mask>'\n",
    "\n",
    "prediction = fill_mask(masked_sentence)\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Predicted token: {prediction[0]['token_str']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with local LLMs. But as they are big models, we need to use quantization them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m bfloat16\n\u001b[1;32m      4\u001b[0m bnb_config \u001b[39m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m      5\u001b[0m     load_in_4bit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,  \u001b[39m# 4-bit quantization\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     bnb_4bit_quant_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnf4\u001b[39m\u001b[39m'\u001b[39m,  \u001b[39m# Normalized float 4\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     bnb_4bit_use_double_quant\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,  \u001b[39m# Second quantization after the first\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     bnb_4bit_compute_dtype\u001b[39m=\u001b[39mbfloat16  \u001b[39m# Computation type\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mmistralai/Mistral-7B-Instruct-v0.1\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     14\u001b[0m     quantization_config\u001b[39m=\u001b[39;49mbnb_config,\n\u001b[1;32m     15\u001b[0m     device_map\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m     token\u001b[39m=\u001b[39;49mHF_API_TOKEN\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    564\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    565\u001b[0m     )\n\u001b[1;32m    566\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3049\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3046\u001b[0m     hf_quantizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3048\u001b[0m \u001b[39mif\u001b[39;00m hf_quantizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 3049\u001b[0m     hf_quantizer\u001b[39m.\u001b[39;49mvalidate_environment(\n\u001b[1;32m   3050\u001b[0m         torch_dtype\u001b[39m=\u001b[39;49mtorch_dtype, from_tf\u001b[39m=\u001b[39;49mfrom_tf, from_flax\u001b[39m=\u001b[39;49mfrom_flax, device_map\u001b[39m=\u001b[39;49mdevice_map\n\u001b[1;32m   3051\u001b[0m     )\n\u001b[1;32m   3052\u001b[0m     torch_dtype \u001b[39m=\u001b[39m hf_quantizer\u001b[39m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[1;32m   3053\u001b[0m     device_map \u001b[39m=\u001b[39m hf_quantizer\u001b[39m.\u001b[39mupdate_device_map(device_map)\n",
      "File \u001b[0;32m~/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:62\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.validate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_environment\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_accelerate_available() \u001b[39mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[0;32m---> 62\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mand the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m         )\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mfrom_tf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m) \u001b[39mor\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mfrom_flax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m sure the weights are in PyTorch format.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from torch import bfloat16\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4-bit quantization\n",
    "    bnb_4bit_quant_type='nf4',  # Normalized float 4\n",
    "    bnb_4bit_use_double_quant=True,  # Second quantization after the first\n",
    "    bnb_4bit_compute_dtype=bfloat16  # Computation type\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    token=HF_API_TOKEN\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
