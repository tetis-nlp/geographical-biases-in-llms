{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Spatial information coverage in training datasets\n",
    "\n",
    "**Authors**\n",
    "\n",
    "| Author      | Affiliation            |\n",
    "|-------------|------------------------|\n",
    "| Rémy Decoupes    | INRAE / TETIS      |\n",
    "| Mathieu Roche  | CIRAD / TETIS |\n",
    "| Maguelonne Teisseire | INRAE / TETIS            |\n",
    "\n",
    "![TETIS](https://www.umr-tetis.fr/images/logo-header-tetis.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "\n",
    "list_of_models = {\n",
    "    'bert': {\n",
    "        'name': 'bert-base-uncased',\n",
    "        'tokenizer': BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "        'model': BertModel.from_pretrained('bert-base-uncased'),\n",
    "        'mask': \"[MASK]\",\n",
    "        'type': \"SLM\"\n",
    "    },\n",
    "    'bert-base-multilingual-uncased':{\n",
    "        'name': 'bert-base-multilingual-uncased',\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('bert-base-multilingual-uncased'),\n",
    "        'model': BertModel.from_pretrained('bert-base-multilingual-uncased'),\n",
    "        'mask': \"[MASK]\",\n",
    "        'type': \"SLM\"\n",
    "    },\n",
    "    'roberta': {\n",
    "        'name': 'roberta-base',\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('roberta-base'),\n",
    "        'model': RobertaModel.from_pretrained('roberta-base'),\n",
    "        'mask': \"<mask>\",\n",
    "        'type': \"SLM\"\n",
    "    },\n",
    "    'xlm-roberta-base': {\n",
    "        'name': 'xlm-roberta-base',\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('xlm-roberta-base'),\n",
    "        'model': RobertaModel.from_pretrained('xlm-roberta-base'),\n",
    "        'mask': \"<mask>\",\n",
    "        'type': \"SLM\"\n",
    "    },\n",
    "    'mistral': {\n",
    "        'name': 'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "        'type': \"LLM_local\"\n",
    "    },\n",
    "    'llama2': {\n",
    "        'name': 'meta-llama/Llama-2-7b-chat-hf',\n",
    "        'type': \"LLM_local\"\n",
    "    },\n",
    "    'chatgpt':{\n",
    "        'name': 'gpt-3.5-turbo-0301',\n",
    "        'type': \"LLM_remote_api\"\n",
    "    },\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initiate API Key**\n",
    "\n",
    "- HuggingFace \n",
    "- OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    " \n",
    "HF_API_TOKEN = getpass.getpass(prompt=\"Your huggingFace API Key\")\n",
    "OPENAI_API_KEY = getpass.getpass(prompt=\"Your OpenAI API Key\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geo Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install countryinfo\n",
    "!pip install shapely\n",
    "!pip install geopandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from countryinfo import CountryInfo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import geopandas as gpd\n",
    "\n",
    "country = CountryInfo()\n",
    "\n",
    "countries = []\n",
    "capitals = []\n",
    "regions = []\n",
    "subregions = []\n",
    "coordinates = []\n",
    "\n",
    "for c in list(country.all().keys()):\n",
    "    country_info = CountryInfo(c)\n",
    "    countries.append(c)\n",
    "    try:\n",
    "        regions.append(country_info.region())\n",
    "    except:\n",
    "        regions.append(np.NAN)\n",
    "    try:\n",
    "        subregions.append(country_info.subregion())\n",
    "    except:\n",
    "        subregions.append(np.NAN)\n",
    "    try:\n",
    "        if country_info.geo_json()[\"features\"][0][\"geometry\"][\"type\"] == \"Polygon\":\n",
    "          coordinates.append(Polygon(country_info.geo_json()[\"features\"][0][\"geometry\"][\"coordinates\"][0]))\n",
    "        else: #MultiPolygon : Take the biggest one\n",
    "          polygons = country_info.geo_json()[\"features\"][0][\"geometry\"][\"coordinates\"]\n",
    "          max_polygon = max(polygons, key=lambda x: len(x[0]))\n",
    "          coordinates.append(Polygon(max_polygon[0]))\n",
    "    except:\n",
    "        coordinates.append(np.NAN)\n",
    "    try:\n",
    "        capitals.append(country_info.capital())\n",
    "    except:\n",
    "        capitals.append(np.NAN)\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'Country': countries,\n",
    "    'Capital': capitals,\n",
    "    'Region': regions,\n",
    "    'Subregion': subregions,\n",
    "    'Coordinates': coordinates\n",
    "}\n",
    "\n",
    "df_countries = pd.DataFrame(data)\n",
    "df_countries = gpd.GeoDataFrame(df_countries, geometry='Coordinates')\n",
    "\n",
    "# Display DataFrame\n",
    "df_countries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 SLMs\n",
    "\n",
    "### 2.1.1 Example\n",
    "\n",
    "Let's see if \"Tapei\" is part of Roberta-base vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "print(f\"Size of {model_name} vocabulary: {len(tokenizer.get_vocab())}\")\n",
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"Taipei\"\n",
    "print(f\"Is {city} (without uppercase) in vocab ?: {str.lower(city) in tokenizer.get_vocab() or str.lower('Ġ' + city) in tokenizer.get_vocab()}\")\n",
    "print(f\"Is {city} (with uppercase) in vocab ?: {city in tokenizer.get_vocab() or str('Ġ' + city) in tokenizer.get_vocab()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"London\"\n",
    "print(f\"Is {city} (without uppercase) in vocab ?: {str.lower(city) in tokenizer.get_vocab() or str.lower('Ġ' + city) in tokenizer.get_vocab()}\")\n",
    "print(f\"Is {city} (with uppercase) in vocab ?: {city in tokenizer.get_vocab() or str('Ġ' + city) in tokenizer.get_vocab()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "def in_vocab(city):\n",
    "    result = False\n",
    "    try:\n",
    "        result = result or str.lower(city) in tokenizer.get_vocab() or str.lower('Ġ' + city) in tokenizer.get_vocab()\n",
    "        result = result or city in tokenizer.get_vocab() or str('Ġ' + city) in tokenizer.get_vocab()\n",
    "    except:\n",
    "        pass\n",
    "    return result\n",
    "\n",
    "df_countries[\"in_vocab\"] = df_countries[\"Capital\"].apply(in_vocab)\n",
    "df_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_by_continent = df_countries.groupby('Region')[f\"in_vocab\"].mean() * 100\n",
    "accuracy_by_continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries.plot(\"in_vocab\", cmap=\"RdYlGn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Local LLMs\n",
    "\n",
    "### 2.2.1 Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_API_TOKEN)\n",
    "\n",
    "print(f\"Size of {model_name} vocabulary: {len(tokenizer.get_vocab())}\")\n",
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"Taipei\"\n",
    "print(f\"Is {city} (without uppercase) in vocab ?: {str.lower(city) in tokenizer.get_vocab() or str.lower('Ġ' + city) in tokenizer.get_vocab()}\")\n",
    "print(f\"Is {city} (with uppercase) in vocab ?: {city in tokenizer.get_vocab() or str('Ġ' + city) in tokenizer.get_vocab()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"London\"\n",
    "print(f\"Is {city} (without uppercase) in vocab ?: {str.lower(city) in tokenizer.get_vocab() or str.lower('Ġ' + city) in tokenizer.get_vocab()}\")\n",
    "print(f\"Is {city} (with uppercase) in vocab ?: {city in tokenizer.get_vocab() or str('Ġ' + city) in tokenizer.get_vocab()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_API_TOKEN)\n",
    "\n",
    "def in_vocab(city):\n",
    "    result = False\n",
    "    try:\n",
    "        result = result or str.lower(city) in tokenizer.get_vocab() or str.lower('Ġ' + city) in tokenizer.get_vocab()\n",
    "        result = result or city in tokenizer.get_vocab() or str('Ġ' + city) in tokenizer.get_vocab()\n",
    "    except:\n",
    "        pass\n",
    "    return result\n",
    "\n",
    "df_countries[\"in_vocab\"] = df_countries[\"Capital\"].apply(in_vocab)\n",
    "df_countries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_by_continent = df_countries.groupby('Region')[f\"in_vocab\"].mean() * 100\n",
    "accuracy_by_continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries.plot(\"in_vocab\", cmap=\"RdYlGn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Remote LLMs\n",
    "\n",
    "### 2.3.1 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"Taipei\"\n",
    "\n",
    "tokenizer.encode(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer.encode(city)) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in tokenizer.encode(city):\n",
    "    print(f\"token {token}: {tokenizer.decode([token])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"London\"\n",
    "\n",
    "tokenizer.encode(city)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "def in_vocab(city):\n",
    "    result = False\n",
    "    try:\n",
    "        if(len(tokenizer.encode(city)) == 1): # no subtokens\n",
    "            result = True\n",
    "    except:\n",
    "        pass\n",
    "    return result\n",
    "\n",
    "df_countries[\"in_vocab\"] = df_countries[\"Capital\"].apply(in_vocab)\n",
    "\n",
    "accuracy_by_continent = df_countries.groupby('Region')[f\"in_vocab\"].mean() * 100\n",
    "accuracy_by_continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries.plot(\"in_vocab\", cmap=\"RdYlGn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 *Going Further*: \n",
    "\n",
    "### 2.4.1 Using other LLMs\n",
    "\n",
    "1. Evaluate other tokenizer form other LLMs like meta/Llama-3, Microsoft/Phi-3 or Alibaba/Qwen1.5\n",
    "2. Use other remote API like Cohere or Groq\n",
    "\n",
    "### 2.4.2 How to explain the very good geographic knowledge of LLMs when, upon questioning their vocabulary, they have few location?\n",
    "\n",
    "**Hypothesis**: LLMs encountered many locations during their training, however, they are drowned out by the quantity of other words. As a result, the subtokens that make up the locations have a good geographical representation when merged.\n",
    "\n",
    "To validate this hypothesis, we could evaluate the proportion of subtokens from LLM and SLM tokenizers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
