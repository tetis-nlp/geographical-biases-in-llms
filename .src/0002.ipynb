{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Correlation between geographic distance and semantic distance\n",
    "\n",
    "**Authors**\n",
    "\n",
    "| Author      | Affiliation            |\n",
    "|-------------|------------------------|\n",
    "| Rémy Decoupes    | INRAE / TETIS      |\n",
    "| Mathieu Roche  | CIRAD / TETIS |\n",
    "| Maguelonne Teisseire | INRAE / TETIS            |\n",
    "\n",
    "![TETIS](https://www.umr-tetis.fr/images/logo-header-tetis.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geo Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: countryinfo in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shapely in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy<2,>=1.14 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from shapely) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (0.14.3)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from geopandas) (1.9.6)\n",
      "Requirement already satisfied: packaging in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from geopandas) (24.0)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from geopandas) (2.2.1)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from geopandas) (2.0.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\n",
      "Requirement already satisfied: certifi in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2024.2.2)\n",
      "Requirement already satisfied: click~=8.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/rdecoupe/PycharmProjects/geographical-biases-in-LLMs/.conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.0 scikit-learn-1.4.1.post1 scipy-1.13.0 threadpoolctl-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install countryinfo\n",
    "!pip install shapely\n",
    "!pip install geopandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from countryinfo import CountryInfo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import geopandas as gpd\n",
    "\n",
    "country = CountryInfo()\n",
    "\n",
    "countries = []\n",
    "capitals = []\n",
    "regions = []\n",
    "subregions = []\n",
    "coordinates = []\n",
    "\n",
    "for c in list(country.all().keys()):\n",
    "    country_info = CountryInfo(c)\n",
    "    countries.append(c)\n",
    "    try:\n",
    "        regions.append(country_info.region())\n",
    "    except:\n",
    "        regions.append(np.NAN)\n",
    "    try:\n",
    "        subregions.append(country_info.subregion())\n",
    "    except:\n",
    "        subregions.append(np.NAN)\n",
    "    try:\n",
    "        if country_info.geo_json()[\"features\"][0][\"geometry\"][\"type\"] == \"Polygon\":\n",
    "          coordinates.append(Polygon(country_info.geo_json()[\"features\"][0][\"geometry\"][\"coordinates\"][0]))\n",
    "        else: #MultiPolygon : Take the biggest one\n",
    "          polygons = country_info.geo_json()[\"features\"][0][\"geometry\"][\"coordinates\"]\n",
    "          max_polygon = max(polygons, key=lambda x: len(x[0]))\n",
    "          coordinates.append(Polygon(max_polygon[0]))\n",
    "    except:\n",
    "        coordinates.append(np.NAN)\n",
    "    try:\n",
    "        capitals.append(country_info.capital())\n",
    "    except:\n",
    "        capitals.append(np.NAN)\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'Country': countries,\n",
    "    'Capital': capitals,\n",
    "    'Region': regions,\n",
    "    'Subregion': subregions,\n",
    "    'Coordinates': coordinates\n",
    "}\n",
    "\n",
    "df_countries = pd.DataFrame(data)\n",
    "df_countries = gpd.GeoDataFrame(df_countries, geometry='Coordinates')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 SLMs\n",
    "\n",
    "### 3.1.1 Example\n",
    "\n",
    "Let's compute the correlation between Taepei and other cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city1 = \"Taepei\"\n",
    "city2 = \"Singapour\"\n",
    "city3 = \"Seoul\"\n",
    "city4 = \"Hanoi\"\n",
    "city5 = \"London\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve **word embedding** from city names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = RobertaModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'city3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m emb1 \u001b[39m=\u001b[39m word_embedding(city1)\n\u001b[1;32m      8\u001b[0m emb2 \u001b[39m=\u001b[39m word_embedding(city2)\n\u001b[0;32m----> 9\u001b[0m emb3 \u001b[39m=\u001b[39m word_embedding(city3)\n\u001b[1;32m     10\u001b[0m emb4 \u001b[39m=\u001b[39m word_embedding(city4)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEmbedding length: \u001b[39m\u001b[39m{\u001b[39;00memb1\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00memb1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'city3' is not defined"
     ]
    }
   ],
   "source": [
    "def word_embedding(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids).last_hidden_state\n",
    "    return last_hidden_states.mean(dim=1)[0] # for words chunked into subtokens (out of model vocabulary) and [CLS] & [SEP]\n",
    "\n",
    "emb1 = word_embedding(city1)\n",
    "emb2 = word_embedding(city2)\n",
    "emb3 = word_embedding(city3)\n",
    "emb4 = word_embedding(city4)\n",
    "emb5 = word_embedding(city5)\n",
    "\n",
    "print(f\"Embedding length: {emb1.shape} \\n\\t{emb1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute **semantic similarity** between the 2 cities' embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9639216]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity([emb1], [emb2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
